{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\anaconda3\\envs\\comp0197-pt\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torcheval.metrics import R2Score\n",
    "from torchmetrics import MeanSquaredError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FEATURES = ['category_encoded',\n",
    "                  'amt', \n",
    "                  'gender_encoded', \n",
    "                  'city_encoded', \n",
    "                  'state_encoded', \n",
    "                  'city_pop', \n",
    "                  'job_encoded', \n",
    "                  'age', \n",
    "                  'hour', \n",
    "                  'daily', \n",
    "                  'day', \n",
    "                  'month']\n",
    "OUTPUT_FEATURE = ['is_fraud']\n",
    "\n",
    "def preprocessing(df):\n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    # drop nA rows containing values\n",
    "    df.dropna(axis=0)\n",
    "    # drop the 'Unnamed: 0'\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    # change the type of date time\n",
    "    df['age'] = df['dob'].apply(lambda x: datetime.now().year - datetime.strptime(x, '%Y-%m-%d').year)\n",
    "    df['trans_datetime'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "    df['hour'] = df['trans_datetime'].dt.hour\n",
    "    df['daily'] = df['trans_datetime'].dt.day\n",
    "    df['day'] = df['trans_datetime'].dt.dayofweek\n",
    "    df['month'] = df['trans_datetime'].dt.month\n",
    "    df.drop('trans_date_trans_time', axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def encoding_columns(df):\n",
    "\n",
    "    labelencoder = LabelEncoder()\n",
    "    df['category_encoded'] = labelencoder.fit_transform(df['category'])\n",
    "    df['gender_encoded'] = labelencoder.fit_transform(df['gender'])\n",
    "    df['city_encoded'] = labelencoder.fit_transform(df['city'])\n",
    "    df['state_encoded'] =labelencoder.fit_transform(df['state'])\n",
    "    df['job_encoded'] = labelencoder.fit_transform(df['job'])\n",
    "\n",
    "    return df\n",
    "class MapStyleFraudDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    \n",
    "def dataloading(for_training, input_features, output_feature):\n",
    "\n",
    "    if for_training:\n",
    "        df = pd.read_csv('../data/fraudTrain.csv')\n",
    "    else:\n",
    "        df = pd.read_csv('../data/fraudTest.csv')\n",
    "    \n",
    "    df = df[df['is_fraud']==0]\n",
    "    df = preprocessing(df)\n",
    "    df = encoding_columns(df)\n",
    "\n",
    "    if for_training:\n",
    "        # split btwn training data and validation with ratio 90%\n",
    "        df_train, df_val = train_test_split(df, test_size=0.1, random_state=42, stratify=df['is_fraud'])\n",
    "\n",
    "        # scale the data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df_train[input_features])\n",
    "\n",
    "        df_train[input_features]=scaler.transform(df_train[input_features])\n",
    "        df_val[input_features]=scaler.transform(df_val[input_features])\n",
    "\n",
    "        # separate Input and Label\n",
    "        X_train = df_train[input_features]\n",
    "        y_train = df_train[output_feature]\n",
    "\n",
    "        X_val = df_val[input_features]\n",
    "        y_val = df_val[output_feature]  \n",
    "\n",
    "        X_train= torch.Tensor(X_train.values)\n",
    "        y_train = torch.Tensor(y_train.values)\n",
    "        X_val= torch.Tensor(X_val.values)\n",
    "        y_val = torch.Tensor(y_val.values)\n",
    "\n",
    "        # change it to Dataloader objects\n",
    "        train_set = MapStyleFraudDataset(X_train,y_train )\n",
    "        val_set = MapStyleFraudDataset(X_val,y_val)\n",
    "\n",
    "        trainloader = DataLoader(train_set, batch_size=64, num_workers=0)\n",
    "        validloader = DataLoader(val_set, batch_size=64, num_workers=0)\n",
    "\n",
    "        return trainloader, validloader\n",
    "\n",
    "    else:\n",
    "\n",
    "        # scale the data\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df[input_features])\n",
    "        df[input_features]=scaler.transform(df[input_features])\n",
    "\n",
    "        X_test = df[input_features]\n",
    "        y_test = df[output_feature]  \n",
    "\n",
    "        X_test= torch.Tensor(X_test.values)\n",
    "        y_test = torch.Tensor(y_test.values)\n",
    "\n",
    "        test_set = MapStyleFraudDataset(X_test,y_test)\n",
    "\n",
    "        testloader = DataLoader(test_set, batch_size=64, num_workers=0)\n",
    "\n",
    "        return testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader = dataloading(for_training=True, input_features=INPUT_FEATURES, output_feature=OUTPUT_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from AE_model import *\n",
    "\n",
    "def train(num_epoch,train_loader, valid_loader, patience, lr, deepAut, intermediate, latent_size):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if deepAut == True:\n",
    "        model = DeepAutoencoder(len(INPUT_FEATURES), intermediate, latent_size )\n",
    "    else:\n",
    "        model = SimpleAutoencoder(len(INPUT_FEATURES), latent_size )\n",
    "        \n",
    "    # Define optimizer\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_val_loss = np.inf\n",
    "    model.train()\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0.0\n",
    "        for i,data in enumerate(train_loader,0):\n",
    "            inputs,_ = data\n",
    "            inputs = inputs.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = nn.MSELoss()(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            print('\\rEpoch: {}\\tbatch: {}\\tLoss =  {:.3f}'.format(epoch, i+1, loss), end=\"\")\n",
    "\n",
    "        print('\\n')\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for data in valid_loader:\n",
    "                inputs,_ = data\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model.forward(inputs)\n",
    "                loss = nn.MSELoss()(outputs, inputs)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            val_loss *= (1/len(valid_loader))   \n",
    "            print(f\"Epoch {epoch+1}: train MSE loss = {running_loss/len(trainloader)}\", f\"|| Valid: MSE loss = {val_loss}\")\n",
    "            \n",
    "        # early-stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            dict_model = model.state_dict()\n",
    "            pat = 0\n",
    "                \n",
    "        else:\n",
    "            pat += 1\n",
    "            print(\"pat \", pat)\n",
    "            if pat == patience:\n",
    "                print(\"Early Stopping: Validation Loss did not decrease for\", patience, \"epochs.\")\n",
    "                break\n",
    "\n",
    "    if deepAut == True:\n",
    "        torch.save(dict_model, f'DeepAutoEncoder_int{intermediate}_lat{latent_size}.pt')\n",
    "    else:\n",
    "        torch.save(dict_model, f'SimpleAutoEncoder_lat{latent_size}.pt')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tbatch: 18129\tLoss =  0.0640\n",
      "\n",
      "Epoch 1: train MSE loss = 0.14532930321752666 || Valid: MSE loss = 0.03739593166016763\n",
      "Epoch: 1\tbatch: 18129\tLoss =  0.014\n",
      "\n",
      "Epoch 2: train MSE loss = 0.01866840498401816 || Valid: MSE loss = 0.013486175624556637\n",
      "Epoch: 2\tbatch: 18129\tLoss =  0.010\n",
      "\n",
      "Epoch 3: train MSE loss = 0.01062702740968156 || Valid: MSE loss = 0.008321654979167299\n",
      "Epoch: 3\tbatch: 18129\tLoss =  0.007\n",
      "\n",
      "Epoch 4: train MSE loss = 0.007199002961722715 || Valid: MSE loss = 0.006302227003952816\n",
      "Epoch: 4\tbatch: 18129\tLoss =  0.006\n",
      "\n",
      "Epoch 5: train MSE loss = 0.005745906753178261 || Valid: MSE loss = 0.005340712857473106\n",
      "Epoch: 5\tbatch: 18129\tLoss =  0.005\n",
      "\n",
      "Epoch 6: train MSE loss = 0.004906558307551009 || Valid: MSE loss = 0.004638771385401626\n",
      "Epoch: 6\tbatch: 18129\tLoss =  0.004\n",
      "\n",
      "Epoch 7: train MSE loss = 0.004401786664249469 || Valid: MSE loss = 0.004203202307776596\n",
      "Epoch: 7\tbatch: 18129\tLoss =  0.004\n",
      "\n",
      "Epoch 8: train MSE loss = 0.004115319992410855 || Valid: MSE loss = 0.003967825065756323\n",
      "Epoch: 8\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 9: train MSE loss = 0.0038812155721413126 || Valid: MSE loss = 0.00379335969477365\n",
      "Epoch: 9\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 10: train MSE loss = 0.0037129321877841393 || Valid: MSE loss = 0.003680221216404168\n",
      "Epoch: 10\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 11: train MSE loss = 0.0036204824384632583 || Valid: MSE loss = 0.0035351493921611577\n",
      "Epoch: 11\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 12: train MSE loss = 0.00352149471045237 || Valid: MSE loss = 0.00346620442743226\n",
      "Epoch: 12\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 13: train MSE loss = 0.0034757415505973087 || Valid: MSE loss = 0.0034152155387025818\n",
      "Epoch: 13\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 14: train MSE loss = 0.0034114576592487425 || Valid: MSE loss = 0.0033568705049073022\n",
      "Epoch: 14\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 15: train MSE loss = 0.003366676113225133 || Valid: MSE loss = 0.0033208547919762158\n",
      "Epoch: 15\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 16: train MSE loss = 0.003337923764798721 || Valid: MSE loss = 0.0032911733319178666\n",
      "Epoch: 16\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 17: train MSE loss = 0.003297199202008236 || Valid: MSE loss = 0.003240052964301461\n",
      "Epoch: 17\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 18: train MSE loss = 0.0032941258056292714 || Valid: MSE loss = 0.0032136660757897508\n",
      "Epoch: 18\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 19: train MSE loss = 0.003255983645198035 || Valid: MSE loss = 0.0031887058712017466\n",
      "Epoch: 19\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 20: train MSE loss = 0.0032359704207659532 || Valid: MSE loss = 0.003157615078995628\n",
      "Epoch: 0\tbatch: 18129\tLoss =  0.0479\n",
      "\n",
      "Epoch 1: train MSE loss = 0.12130240547819102 || Valid: MSE loss = 0.03021917648049575\n",
      "Epoch: 1\tbatch: 18129\tLoss =  0.006\n",
      "\n",
      "Epoch 2: train MSE loss = 0.01437193193675122 || Valid: MSE loss = 0.008925041493499842\n",
      "Epoch: 2\tbatch: 18129\tLoss =  0.004\n",
      "\n",
      "Epoch 3: train MSE loss = 0.005945246803454156 || Valid: MSE loss = 0.004229111014229821\n",
      "Epoch: 3\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 4: train MSE loss = 0.0037677322130901902 || Valid: MSE loss = 0.003255139635274968\n",
      "Epoch: 4\tbatch: 18129\tLoss =  0.003\n",
      "\n",
      "Epoch 5: train MSE loss = 0.0030785307144190264 || Valid: MSE loss = 0.002733651591521496\n",
      "Epoch: 5\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 6: train MSE loss = 0.002671509870729725 || Valid: MSE loss = 0.0024286632559541842\n",
      "Epoch: 6\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 7: train MSE loss = 0.0024627656966078695 || Valid: MSE loss = 0.0022649857125022024\n",
      "Epoch: 7\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 8: train MSE loss = 0.0023256613605936245 || Valid: MSE loss = 0.002233424831760086\n",
      "Epoch: 8\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 9: train MSE loss = 0.002227520588648054 || Valid: MSE loss = 0.002090918110474417\n",
      "Epoch: 9\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 10: train MSE loss = 0.002140694842953366 || Valid: MSE loss = 0.0020517946336483096\n",
      "Epoch: 10\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 11: train MSE loss = 0.002105100943116704 || Valid: MSE loss = 0.002039566634092295\n",
      "Epoch: 11\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 12: train MSE loss = 0.002053255605216569 || Valid: MSE loss = 0.0019421332180107164\n",
      "Epoch: 12\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 13: train MSE loss = 0.0020142608495024913 || Valid: MSE loss = 0.0019529468448088497\n",
      "pat  1\n",
      "Epoch: 13\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 14: train MSE loss = 0.0019937014550090865 || Valid: MSE loss = 0.001904987000713527\n",
      "Epoch: 14\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 15: train MSE loss = 0.0019524616474710875 || Valid: MSE loss = 0.0019137228888352043\n",
      "pat  1\n",
      "Epoch: 15\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 16: train MSE loss = 0.0019526204079752464 || Valid: MSE loss = 0.0018848810934232866\n",
      "Epoch: 16\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 17: train MSE loss = 0.0019061469188302242 || Valid: MSE loss = 0.0018552963683444073\n",
      "Epoch: 17\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 18: train MSE loss = 0.0018960765786153173 || Valid: MSE loss = 0.0018425505224554095\n",
      "Epoch: 18\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 19: train MSE loss = 0.001865778811779674 || Valid: MSE loss = 0.0018357374209236983\n",
      "Epoch: 19\tbatch: 18129\tLoss =  0.002\n",
      "\n",
      "Epoch 20: train MSE loss = 0.0018485610258447244 || Valid: MSE loss = 0.001823876781369474\n",
      "Epoch: 0\tbatch: 18129\tLoss =  0.4559\n",
      "\n",
      "Epoch 1: train MSE loss = 0.5585871691001257 || Valid: MSE loss = 0.519442410208747\n",
      "Epoch: 1\tbatch: 18129\tLoss =  0.4272\n",
      "\n",
      "Epoch 2: train MSE loss = 0.4639817200655761 || Valid: MSE loss = 0.5069937502480026\n",
      "Epoch: 2\tbatch: 18129\tLoss =  0.4170\n",
      "\n",
      "Epoch 3: train MSE loss = 0.46029323333873007 || Valid: MSE loss = 0.5056031182001601\n",
      "Epoch: 3\tbatch: 18129\tLoss =  0.4098\n",
      "\n",
      "Epoch 4: train MSE loss = 0.45932657768698865 || Valid: MSE loss = 0.5051114420293282\n",
      "Epoch: 4\tbatch: 18129\tLoss =  0.4037\n",
      "\n",
      "Epoch 5: train MSE loss = 0.45890169244711054 || Valid: MSE loss = 0.5048835691092328\n",
      "Epoch: 5\tbatch: 18129\tLoss =  0.3987\n",
      "\n",
      "Epoch 6: train MSE loss = 0.4586719923353056 || Valid: MSE loss = 0.5047340229190609\n",
      "Epoch: 6\tbatch: 18129\tLoss =  0.3949\n",
      "\n",
      "Epoch 7: train MSE loss = 0.4585297597185171 || Valid: MSE loss = 0.504601352268058\n",
      "Epoch: 7\tbatch: 18129\tLoss =  0.3927\n",
      "\n",
      "Epoch 8: train MSE loss = 0.45843505906555027 || Valid: MSE loss = 0.5044698568490835\n",
      "Epoch: 8\tbatch: 18129\tLoss =  0.3895\n",
      "\n",
      "Epoch 9: train MSE loss = 0.4583695802217653 || Valid: MSE loss = 0.5043391934843277\n",
      "Epoch: 9\tbatch: 18129\tLoss =  0.3889\n",
      "\n",
      "Epoch 10: train MSE loss = 0.4583237987009411 || Valid: MSE loss = 0.5042162833083652\n",
      "Epoch: 10\tbatch: 18129\tLoss =  0.3862\n",
      "\n",
      "Epoch 11: train MSE loss = 0.4582916811380655 || Valid: MSE loss = 0.5041077230023983\n",
      "Epoch: 11\tbatch: 18129\tLoss =  0.3856\n",
      "\n",
      "Epoch 12: train MSE loss = 0.4582687206556059 || Valid: MSE loss = 0.5040153298277417\n",
      "Epoch: 12\tbatch: 18129\tLoss =  0.3842\n",
      "\n",
      "Epoch 13: train MSE loss = 0.4582518391663375 || Valid: MSE loss = 0.5039380909047707\n",
      "Epoch: 13\tbatch: 18129\tLoss =  0.3849\n",
      "\n",
      "Epoch 14: train MSE loss = 0.4582391045529368 || Valid: MSE loss = 0.5038744294465919\n",
      "Epoch: 14\tbatch: 18129\tLoss =  0.3839\n",
      "\n",
      "Epoch 15: train MSE loss = 0.45822931958366675 || Valid: MSE loss = 0.5038220416967094\n",
      "Epoch: 15\tbatch: 18129\tLoss =  0.3830\n",
      "\n",
      "Epoch 16: train MSE loss = 0.45822158873235735 || Valid: MSE loss = 0.5037785875886013\n",
      "Epoch: 16\tbatch: 9773\tLoss =  0.4522"
     ]
    }
   ],
   "source": [
    "deepAuts = [True, True, False, False]\n",
    "intermediates = [50, 100, 1, 1]\n",
    "latents = [10, 10, 6, 4]\n",
    "\n",
    "for i in range(len(deepAuts)):\n",
    "    model = train(num_epoch=20, train_loader=trainloader, valid_loader=validloader, patience=5, lr=2e-4, deepAut=deepAuts[i], intermediate=intermediates[i], latent_size = latents[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0197-pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
